import feedparser
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from dateutil import parser as date_parser
from kafka import KafkaProducer
import json
import time

# âœ… Kafka ì„¤ì •
KAFKA_BROKER = "kafka:9092"
TOPIC = "news"

producer = KafkaProducer(
    bootstrap_servers=KAFKA_BROKER,
    value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode('utf-8')
)

# âœ… RSS í”¼ë“œ URL
RSS_FEED_URL = "https://www.hankyung.com/feed/it"

# âœ… ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜
def get_article_content(url: str) -> str:
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"
        }
        res = requests.get(url, headers=headers, timeout=5)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ë³¸ë¬¸ ì˜ì—­ ì„ íƒì
        possible_selectors = [
            '.article-body', 
            '.article-text', 
            '#articletxt',
            '.article-contents',
            '#newsView',
            '.news-contents',
            '[itemprop="articleBody"]'
        ]
        
        article_div = None
        for selector in possible_selectors:
            article_div = soup.select_one(selector)
            if article_div:
                break

        if not article_div:
            print(f"â— ë³¸ë¬¸ div ì—†ìŒ: {url}")
            return None

        # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
        for tag in article_div.select('.promotion_wrap, .article_ad, .article_footer, script, style, .article-tools, .article-bottom, .article-sns, .copyright, iframe, .article-relation-news'):
            tag.decompose()

        # ë³¸ë¬¸ ë¬¸ë‹¨ ì¶”ì¶œ ë° ì •ì œ
        paragraphs = []
        
        # 1. ë¨¼ì € êµ¬ì¡°í™”ëœ ë¬¸ë‹¨ ì°¾ê¸°
        content_elements = article_div.select('p, .paragraph, .content, [itemprop="articleBody"] > div')
        
        if not content_elements:
            # 2. êµ¬ì¡°í™”ëœ ë¬¸ë‹¨ì´ ì—†ìœ¼ë©´ ì§ì ‘ í…ìŠ¤íŠ¸ ë¶„ë¦¬
            text = article_div.get_text('\n', strip=True)
            paragraphs = [p.strip() for p in text.split('\n') if p.strip()]
        else:
            for element in content_elements:
                text = element.get_text(strip=True)
                if text:
                    paragraphs.append(text)

        # ë¶ˆí•„ìš”í•œ ë¬¸ë‹¨ í•„í„°ë§
        filtered_paragraphs = []
        skip_patterns = [
            'â–¶', 'Â©', 'ì €ì‘ê¶Œì', 'ë¬´ë‹¨ì „ì¬', 'ë°°í¬ê¸ˆì§€', 'â–¼', 
            'ê´€ë ¨ê¸°ì‚¬', 'í•œê²½ë‹·ì»´', 'ë„¤ì´ë²„ì—ì„œ í•œêµ­ê²½ì œ ë‰´ìŠ¤ë¥¼',
            'êµ¬ë…í•˜ê¸°', 'ì¢‹ì•„ìš”', 'ê³µìœ í•˜ê¸°', 'ë©”ì¼ë³´ë‚´ê¸°',
            'ë³¸ë¬¸ ë‚´ìš©ê³¼ URLì„ ë³µì‚¬í•©ë‹ˆë‹¤', 'ë‹«ê¸°'
        ]
        
        for p in paragraphs:
            if p and len(p) > 10 and not any(skip in p for skip in skip_patterns):
                filtered_paragraphs.append(p)

        # ë¬¸ë‹¨ ì‚¬ì´ì— ë¹ˆ ì¤„ì„ ì¶”ê°€í•˜ì—¬ ê²°í•©
        content = '\n\n'.join(filtered_paragraphs)
        
        # ë³¸ë¬¸ ê¸¸ì´ ì²´í¬ ê¸°ì¤€ ì¶”ê°€ ì™„í™”
        if len(content.strip()) < 30:  # ê¸°ì¤€ê°’ì„ ë” ë‚®ì¶¤
            print(f"â›” ë³¸ë¬¸ ë„ˆë¬´ ì§§ìŒ: {url}")
            return None

        return content.strip()

    except Exception as e:
        print(f"â— í¬ë¡¤ë§ ì—ëŸ¬: {url} â†’ {e}")
        return None

# âœ… ë©”ì¸ ë¡œì§
def main():
    print("ğŸ“¡ í•œêµ­ê²½ì œ IT ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘\n")
    feed = feedparser.parse(RSS_FEED_URL)
    print(f"ì´ ê¸°ì‚¬ ìˆ˜: {len(feed.entries)}")

    for entry in feed.entries:
        content = get_article_content(entry.link)

        if content is None:
            print(f"â›” ë³¸ë¬¸ ëˆ„ë½ â†’ Kafka ì „ì†¡ ìƒëµ: {entry.link}")
            continue

        article = {
            "title": entry.title,
            "writer": entry.get("author", "í•œêµ­ê²½ì œ"),
            "write_date": date_parser.parse(entry.get("published", "2025-01-01T00:00:00")).isoformat(),
            "content": content,
            "url": entry.link,
            "keywords": []
        }

        # âœ… Kafka ì „ì†¡
        producer.send(TOPIC, value=article)
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] âœ… Kafka ì „ì†¡ ì™„ë£Œ: {article['title']}")

    print("\nğŸ› ï¸ Kafka Producer ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
