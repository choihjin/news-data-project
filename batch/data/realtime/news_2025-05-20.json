{"title": "[5월19일] \"AI 챗봇은 사실만 말해주지 않아...검색처럼 '팩트 체크' 필수\"", "write_date": "2025-05-20 07:00:00", "category": "AI", "content": "지난 주말 미국에서는 인공지능(AI) 챗봇 '그록'의 답변 문제가 시선을 끌었습니다. 묻지도 않은 남아프리카공화국의 백인 역차별 문제를 설명하는 현상이 일어나, 정치적인 의도가 있는 것이 아니냐는 지적을 받은 것입니다.\nxAI는 이 문제가 일부 직원의독단적인 코드 변경에 따른 것이며, 조직적으로 벌인 일이 아니라고 해명했습니다.\n하지만, 모든 사람이 설득된 것은 아닌 것으로 보입니다. 한 X(트위터) 사용자는 \"코드 수정이 내부 조직의 검토 없이 개인 권한으로 이뤄졌다는 것은 믿기 어렵다\"라며 \"만약 그렇다면 그록은 해킹 한번으로 뚫릴 만큼 보안에 심각한 문제가 있는 것\"이라고 지적했습니다.\n또 다른 사용자는 \"X와 관련된 인물 중 자제력이 부족하고, 늦게 자고, 필요한 접근 권한을 가질 가능성이 높고, 남아공 정치에 대한 특정 견해를 가진 사람이 누구인지 추측해 보라\"는 글을 올렸습니다. 모두 일론 머스크 CEO의 지시에 따른 것이라는 것을 암시한 글입니다.\n이번 일을 일으킨 사람이 머스크 CEO인지 아닌지를 넘어, 전달된 메시지는 명백합니다. AI 챗봇의 말을 모두 믿기 어렵다는 것입니다.\nAI가 뉴스와 같은 사실 확인에 취약하다는 말은 이전에도 등장했습니다.\n지난 2월영국의 공영방송 BBC는 챗GPT와 코파일럿, 제미나이 퍼플렉시티에 BBC 기사를 출처로 사용해 최신 뉴스에 대한 질문에 답하도록 요청한 결과, 챗봇 답변의 51%가 심각한 문제를 보였다고 밝혔습니다. 답변의 19%는 사실적 오류를 챗봇이 직접 추가한 것으로 나타났고, 인용문의 13%는 링크의 내용과 다르거나 전혀 포함되지 않은 것이었습니다.\n이어 3월컬럼비아 저널리즘 리뷰에 게재된 연구에서도 8개의 주요 생성 AI 도구는 60%의 경우 기사 출처를 올바르게 식별하지 못하는 것으로 나타났습니다. 퍼플렉시티의 실패율이 37%로 가장 좋은 편이었으며, 그록은 질의의 94%에 잘못 답했습니다.\n특히 AI 도구는 오답을 제시하는 과정에서 \"놀라울 정도로 자신감 넘치는 모습을 보였다\"라는 분석입니다. 예를 들어, 챗GPT는 134개의 기사를 잘못 식별했지만, 총 200건의 응답 중 근거가 부족하다고 밝힌 경우는 15건에 불과했으며, 잘 모르겠다고 밝힌 경우는 한번도 없었습니다.\n챗봇이 정확하게 답할 수 없는 질문에도 답변을 거부하는 대신, 부정확하거나 추측적인 답변을 제공하는 경향이 있다는 것입니다. 링크를 조작하는 경우도 나왔습니다.\nAI 검색의 오류 문제는 LLM의 '환각'을 넘어섭니다. 환각은 정답이 없어도 억지로 만들어 내는 과정에서 생기는 기술적인 문제인 반면, AI 검색은 실시간으로 인터넷의 잘못된 정보를 추가할 수 있기 때문입니다. 인터넷에는 잘못되거나 편향된 정보들이 넘쳐 납니다.\n지난해 구글의 AI 검색도 마찬가지였습니다. \"피자에 접착제를 붙이라\"는 답변은 제미나이가 지어낸 것이 아니라, 누군가 우스개로 올린 블로그 글을 인용했기 때문입니다.\n특히 그록은 X에서 실시간으로 정보를 가져옵니다. 머스크 CEO의 인수 이후 트위터가 정치적으로 많이 기울었으며, 허위 정보나 음모론이 퍼져 있다는 것도 잘 알려져 있습니다. 여기에서 정보를 가져온 그록이 민감한 상황에 대해 어떤 답을 내놓을지는 뻔합니다.\n여기에 독일 매체인 DW는 AI 챗봇이 이미지 분석에서도 사실 확인에 취약하다고 보도했습니다. 예를 들어, 그록은 오픈AI의 '소라'가 생성한 가짜 아나콘다 영상을 사실이라고 주장했습니다. 영상 귀퉁이에는 소라가 생성한 것이라는 워터마크가 들어가 있었습니다.\nhttps://twitter.com/i/status/1922423204905164828\n최근 국내의 AI 챗봇 사용자 비율이휴대폰 사용자의 절반에 달한다는 데이터가 등장했습니다. 또 상당수는 검색을 위한 용도로 활용하는 것으로 알려졌습니다. AI 챗봇은 기존 검색보다 사용하기 편합니다.\n그러나 기존 검색 결과에 나온 링크를 모두 사실이라고 믿지 않는 것처럼, 챗봇에도 그런 자세가 필요하다는 것입니다.\nAI 챗봇은 모든 사실을 알고 있는 존재가 아닙니다. 인터넷에 있는 모든 지식을 학습했을지는 모르지만, 거기에는 잘못된 지식도 많이 포함됐고, 사실 여부와 관계없이 무언가를 반드시 답해야 하는 구조 때문에 없는 사실도 만들어 냅니다.\n전문가들도 이런 점을 강조합니다. 펠릭스 사이먼 옥스포드 인터넷 연구소 연구원은 \"그록이나 메타 AI, 챗GPT와 같은 AI 시스템은 '팩트 체크 도구'로 간주해서는 안 된다. 일부 간단한 사실 확인에는 유용할 수 있지만, 답변을 다른 출처와 다시 한번 비교하고 확인해야 한다\"라고 말했습니다.\n이어 주말 주요 뉴스입니다.\n■오픈AI, 코딩 에이전트 '코덱스' 세부 정보 공개...\"AI 도구 넘어 동료로 발전할 것\"\n코덱스가 현재 '코딩 병렬 작업'을 넘어 앞으로는 진행 상황을 실시간으로 전달하고 의견을 묻고 자잘한 업무를 처리하는 등 AI 동료가 될 것이라는 설명입니다. '에이전트'라는 이름을 붙이려면, 사실 이 정도는 돼야 합니다.\n■코딩 AI 사용량 75% 급증...'챗GPT'는 분야별 전문 AI 사용자 흡수\nAI 도구가 크게 2가지로 압축되는 모습입니다. 코딩 AI는 에이전트로 발전하거나 시스템에 통합되고, 나머지 챗봇 기능이나 이미지 생성 등은 모두 챗GPT와 같은 범용 챗봇에 흡수되는 것입니다.\n■\"엔비디아, 상하이에 R&D 센터 설립...중국 내 영향력 유지할 것\"\n미국의 수출 규제로 중국이 자체 칩 개발에 매달릴 것에 대비, 엔비디아가 중국 고객들을 위한 현지의 R&D 센터를 구축한다는 소식입니다. 어찌보면 중국 AI 발전을 '효과적으로 늦추는 방법'을 찾는 것입니다.\n임대준 기자 ydj@aitimes.com", "keywords": ["인공지능", "챗봇", "그록", "사실 확인", "일론 머스크"], "url": "https://www.aitimes.com/news/articleView.html?idxno=170539"}
